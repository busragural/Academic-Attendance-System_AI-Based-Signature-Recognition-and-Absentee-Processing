# -*- coding: utf-8 -*-
"""signature_comparison_with_snn.ipynb

Automatically generated by Colab.

# Signature Comparison with Siamese Neural Network (SNN)

***Image Size***
- 128 x 128

***Input Type***
- two different inputs

***Input Shape***
- 128 x 128 x 1

***Measurement Type***
- euclidean distance

## Libraries
"""

!pip install colorama -q

import warnings
warnings.filterwarnings('ignore')

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# import os
# import cv2
# import time
# import numpy as np
# import pandas as pd
# import seaborn as sns
# import tensorflow as tf
# import matplotlib.pyplot as plt
# from sklearn.metrics import confusion_matrix
# from google.colab import drive
# from keras import callbacks
# from keras.models import Model, Sequential
# from keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, Input, Lambda, MaxPooling2D, ZeroPadding2D
# from keras.regularizers import l1_l2
# from keras import backend as K
# from IPython.display import HTML
# from colorama import Fore, Style

"""## Data Paths"""

# mounting google drive
drive.mount('/content/drive')

# define data paths
project_path = "/content/drive/MyDrive/Datasets/signature_comparison_project"
data_dir = f"{project_path}/sign_data"
data_trial_dir = f"{project_path}/trial_data"
data_notebook_dir = f"{project_path}/notebook_data"
csv_path = f"{project_path}/data_comparison.csv"
csv_path_train = f"{project_path}/data_comparison_train.csv"
csv_path_val = f"{project_path}/data_comparison_val.csv"
csv_path_test = f"{project_path}/data_comparison_test.csv"

"""## Data Information"""

# define column names for the dataset
columns = ['Image1', 'Image2', 'Label']

# read CSV files
data_csv = pd.read_csv(csv_path, header=None, names=columns)
train_data_csv = pd.read_csv(csv_path_train, header=None, names=columns)
val_data_csv = pd.read_csv(csv_path_val, header=None, names=columns)
test_data_csv = pd.read_csv(csv_path_test, header=None, names=columns)

# display the first few observations of the dataset
data_csv.head()

# display the last few observations of the dataset
data_csv.tail()

# display statistical summary of the dataset
data_csv.describe().T

# print the class distribution in the dataset
class_distribution = [data_csv['Label'].value_counts(), train_data_csv['Label'].value_counts(),
                      val_data_csv['Label'].value_counts(), test_data_csv['Label'].value_counts()]

print("Class Distribution in the Dataset")

for label, count in class_distribution[0].items():
    print(f"- (all)   frequency of class {label}: {count}")
print()

for label, count in class_distribution[1].items():
    print(f"- (train) frequency of class {label}: {count}")
print()

for label, count in class_distribution[2].items():
    print(f"- (val)   frequency of class {label}: {count}")
print()

for label, count in class_distribution[3].items():
    print(f"- (test)  frequency of class {label}: {count}")

# visualize class distribution in the dataset
plt.figure(figsize=(3, 3))
data_csv['Label'].value_counts().plot(kind='bar', color='skyblue')
plt.title('Class Distribution in the Dataset')
plt.xlabel('Class')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()

"""## Data Processing"""

# define image size
img_size = (128, 128)

# function to process all data
def process_data(data, dir_data, img_size):
    start_time = time.time()

    X_data = []
    y_data = []

    for idx, row in data.iterrows():
        img_path1 = os.path.join(dir_data, row['Image1'])
        img_path2 = os.path.join(dir_data, row['Image2'])
        label = int(row['Label'])

        img1 = cv2.imread(img_path1, cv2.IMREAD_GRAYSCALE)
        if img1 is None:
            print(f"Error: Unable to load image at {img_path1}")
            continue
        img1 = cv2.resize(img1, img_size)
        img1 = cv2.GaussianBlur(img1, (3, 3), 0)
        img1 = cv2.adaptiveThreshold(img1, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 29, 11)
        img1 = cv2.normalize(img1, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)

        img2 = cv2.imread(img_path2, cv2.IMREAD_GRAYSCALE)
        if img2 is None:
            print(f"Error: Unable to load image at {img_path2}")
            continue
        img2 = cv2.resize(img2, img_size)
        img2 = cv2.GaussianBlur(img2, (3, 3), 0)
        img2 = cv2.adaptiveThreshold(img2, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 29, 11)
        img2 = cv2.normalize(img2, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)

        X_data.append([img1, img2])
        y_data.append(label)

    end_time = time.time()
    elapsed_time = end_time - start_time
    minutes, seconds = divmod(elapsed_time, 60)
    print(f"Data processing time: {int(minutes)} minutes and {seconds:.2f} seconds")

    return np.array(X_data), np.array(y_data)

# process the data
X_train, y_train = process_data(train_data_csv, data_dir, img_size)
X_val, y_val = process_data(val_data_csv, data_dir, img_size)
X_test, y_test = process_data(test_data_csv, data_dir, img_size)

# save the data
np.save(f"{data_notebook_dir}/X_train.npy", X_train)
np.save(f"{data_notebook_dir}/y_train.npy", y_train)

np.save(f"{data_notebook_dir}/X_val.npy", X_val)
np.save(f"{data_notebook_dir}/y_val.npy", y_val)

np.save(f"{data_notebook_dir}/X_test.npy", X_test)
np.save(f"{data_notebook_dir}/y_test.npy", y_test)

# load the data
X_train = np.load(f"{data_notebook_dir}/X_train_old.npy")
y_train = np.load(f"{data_notebook_dir}/y_train_old.npy")

X_val = np.load(f"{data_notebook_dir}/X_val_old.npy")
y_val = np.load(f"{data_notebook_dir}/y_val_old.npy")

X_test = np.load(f"{data_notebook_dir}/X_test_old.npy")
y_test = np.load(f"{data_notebook_dir}/y_test_old.npy")

# display data types
print("Data type of X :", type(X_train))
print("Data type of y :", type(y_train))

# display data shapes
print(f"Shape of X_train : {X_train.shape}")
print(f"Shape of y_train : {y_train.shape}\n")

print(f"Shape of X_val : {X_val.shape}")
print(f"Shape of y_val : {y_val.shape}\n")

print(f"Shape of X_test : {X_test.shape}")
print(f"Shape of y_test : {y_test.shape}")

"""## Functions to Create, Compile, Train and Evaluate the Model"""

# function to visualize confusion matrix
def display_confusion_matrix(model, X_data, y_data, threshold=0.7):
    y_pred = model.predict([X_data[:, 0], X_data[:, 1]])
    y_pred = (y_pred >= threshold).astype(int)
    cm = confusion_matrix(y_data, y_pred)
    plt.figure(figsize=(5, 5))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["0", "1"], yticklabels=["0", "1"])
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()

# euclidean distance function
def euclidean_distance(vectors):
    vector1, vector2 = vectors
    sum_square = K.sum(K.square(vector1 - vector2), axis=1, keepdims=True)
    return K.sqrt(K.maximum(sum_square, K.epsilon()))

# contrastive loss function
def contrastive_loss(label, distance, margin=1.0, alpha=1.25, beta=1.0):
    distance = tf.cast(distance, dtype=tf.float32)
    label = tf.cast(label, dtype=tf.float32)

    loss_same = (1 - label) * K.square(distance)
    loss_diff = label * K.square(K.maximum(margin - distance, 0))

    weighted_loss_same = alpha * loss_same
    weighted_loss_diff = beta * loss_diff

    loss = K.mean(weighted_loss_same + weighted_loss_diff)

    return loss

# 1st metric function - custom_accuracy
def custom_accuracy(label, distance, threshold=0.7):
    distance = tf.cast(distance, dtype=tf.float32)
    distance_binary = tf.cast(distance >= threshold, dtype=tf.float32)
    accuracy = tf.reduce_mean(tf.cast(tf.equal(label, distance_binary), dtype=tf.float32))
    return accuracy

# 2nd metric function - precision
def precision(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

# 3rd metric function - recall
def recall(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall

# 4th metric function - f1_score
def f1_score(y_true, y_pred):
    precision_value = precision(y_true, y_pred)
    recall_value = recall(y_true, y_pred)
    f1_score = 2 * ((precision_value * recall_value) / (precision_value + recall_value + K.epsilon()))
    return f1_score

# function to create snn model
def create_snn_model(input_shape: tuple) -> Model:
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Conv2D(256, (3, 3), activation='relu'),
        MaxPooling2D((2, 2)),
        Flatten(name='flatten'),
        Dense(1024, activation='relu', kernel_regularizer=l1_l2(0.00005)),
        Dropout(0.2),
        Dense(512, activation='relu'),
        Dropout(0.2),
        Dense(256, activation='relu'),
        Dropout(0.2),
        Dense(128, activation='relu')
    ])
    input1 = Input(shape=input_shape)
    input2 = Input(shape=input_shape)

    encoded_input1 = model(input1)
    encoded_input2 = model(input2)

    distance = Lambda(euclidean_distance, output_shape=(1,))([encoded_input1, encoded_input2])

    output = Dense(1, activation='sigmoid')(distance)

    snn_model = Model(inputs=[input1, input2], outputs=output)

    return snn_model

# funtion to visualize for model performance
def plot_metrics(title, xlabel, ylabel, legend, *histories):
    for history in histories:
        plt.plot(history)
    plt.title(title)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.legend(legend, loc='upper left')
    plt.show()

"""## Model Building and Training"""

# create SNN model
model = create_snn_model((*img_size, 1))

# compile the model
# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy', custom_accuracy, f1_score])
# model.compile(optimizer='rmsprop', loss=contrastive_loss, metrics=['accuracy', custom_accuracy, precision, recall, f1_score])
# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', custom_accuracy, f1_score])
model.compile(optimizer='adam', loss=contrastive_loss, metrics=['accuracy', custom_accuracy, precision, recall, f1_score])

# display model architecture
model.summary()

# define early stopping
early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# model.load_weights(f"{data_notebook_dir}/model_snn_colab_real.h5")
# train the model
history = model.fit([X_train[:, 0], X_train[:, 1]],
                    y_train,
                    batch_size=256,
                    epochs=15,
                    callbacks=[early_stopping],
                    validation_data=([X_val[:, 0], X_val[:, 1]], y_val))

# save the model
model.save(f"{data_notebook_dir}/model_snn_colab.h5", overwrite=True)

# load the model (weights)
model.load_weights(f"{data_notebook_dir}/model_snn_colab.h5")

"""## Model Evaluation"""

# evaluate the model on train set
results_train = model.evaluate([X_train[:, 0], X_train[:, 1]], y_train)
print(f"-> Train Loss\t\t: {results_train[0]:.5f}")
print(f"-> Train Accuracy\t: {results_train[1]:.5f}\n")

# evaluate the model on validation set
results_val = model.evaluate([X_val[:, 0], X_val[:, 1]], y_val)
print(f"-> Validation Loss\t: {results_val[0]:.5f}")
print(f"-> Validation Accuracy\t: {results_val[1]:.5f}\n")

# evaluate the model on test set
results_test = model.evaluate([X_test[:, 0], X_test[:, 1]], y_test)
print(f"-> Test Loss\t\t: {results_test[0]:.5f}")
print(f"-> Test Accuracy\t: {results_test[1]:.5f}")

# confusion matrix for training data
display_confusion_matrix(model, X_train, y_train)

# confusion matrix for validation data
display_confusion_matrix(model, X_val, y_val)

# confusion matrix for test data
display_confusion_matrix(model, X_test, y_test)

# plot training & validation accuracy values
plot_metrics('Model Accuracy', 'Epoch', 'Accuracy', ['Train', 'Validation'], history.history['accuracy'], history.history['val_accuracy'])

# plot training & validation loss values
plot_metrics('Model Loss', 'Epoch', 'Loss', ['Train', 'Validation'], history.history['loss'], history.history['val_loss'])

# plot f1-score values
plot_metrics('F1-Score', 'Epoch', 'Rate', ['F1 Score'], history.history['f1_score'])

"""## Other Model Evaluation Functions for More Detailed Review"""

# random data selection function
def choose_random_signature(csv_path, data_dir):
    df = pd.read_csv(csv_path)

    random_row = df.sample(n=1)

    path1 = data_dir + "/" + random_row.iloc[0, 0]
    path2 = data_dir + "/" + random_row.iloc[0, 1]
    label = random_row.iloc[0, 2]

    return path1, path2, label

# data processing function for single image
def process_single_image(image_path, img_size):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    resized_img = cv2.resize(img, img_size)
    blurred_img = cv2.GaussianBlur(resized_img, (3, 3), 0)
    thresholded_img = cv2.adaptiveThreshold(blurred_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 29, 11)
    processed_img = cv2.normalize(thresholded_img, None, 0, 1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)
    return processed_img

# function to calculate similarity score
def calculate_similarity_score(distance: np.ndarray) -> float:
    number = 0.999 - (distance[0][0] * 0.025)
    sim_score = (1 - distance[0][0]) / 0.5
    sim_score = max(0, min(number, sim_score))
    return sim_score

# model prediction function
def model_prediction_function(model, csv_path, data_dir):
    path1, path2, label = choose_random_signature(csv_path, data_dir)

    img1 = process_single_image(path1, img_size)
    img2 = process_single_image(path2, img_size)

    tmp_img1 = np.expand_dims(img1, axis=0)
    tmp_img2 = np.expand_dims(img2, axis=0)

    distance = model.predict([tmp_img1, tmp_img2])

    similarity_score = calculate_similarity_score(distance)

    return path1, path2, label, img1, img2, distance, similarity_score

# result function
def print_result(path1, path2, correct_answer, distance, similarity_score):
    true_class = 'original' if correct_answer == 0 else 'forged / different'
    print(f"- path of first image    : {path1}")
    print(f"- path of second image   : {path2}")
    print(f"- correct answer (label) : {correct_answer} ({true_class})")
    print(f"- euclidean distance     : {distance[0][0]:.3f}")
    print(f"- similarity score       : {similarity_score:.3f}")
    if label == 0:
        print(f"{Fore.GREEN}-> RIGHT GUESS!{Style.RESET_ALL}\n" if similarity_score >= 0.7 else f"{Fore.RED}-> WRONG GUESS!{Style.RESET_ALL}\n")
    else:
        print(f"{Fore.GREEN}-> RIGHT GUESS!{Style.RESET_ALL}\n" if similarity_score < 0.7 else f"{Fore.RED}-> WRONG GUESS!{Style.RESET_ALL}\n")

# function to visualize signatures
def display_images(image1, image2):
    plt.figure(figsize=(4, 2))

    plt.subplot(1, 2, 1)
    plt.imshow(image1, cmap='gray')
    plt.title('Image 1')
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.imshow(image2, cmap='gray')
    plt.title('Image 2')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

"""## Tests on Training, Validation and Test Sets

### Single Tests

#### Test 1
"""

# random data selection, image processing and model prediction
path1, path2, label, img1, img2, distance, similarity_score = model_prediction_function(model, csv_path, data_dir)

# get the result
print_result(path1, path2, label, distance, similarity_score)

# view signatures
display_images(img1, img2)

"""#### Test 2"""

# random data selection, image processing and model prediction
path1, path2, label, img1, img2, distance, similarity_score = model_prediction_function(model, csv_path, data_dir)

# get the result
print_result(path1, path2, label, distance, similarity_score)

# view signatures
display_images(img1, img2)

"""#### Test 3"""

# random data selection, image processing and model prediction
path1, path2, label, img1, img2, distance, similarity_score = model_prediction_function(model, csv_path, data_dir)

# get the result
print_result(path1, path2, label, distance, similarity_score)

# view signatures
display_images(img1, img2)

"""### 10 Random Tests with For Loop"""

# estimate the similarity rate between randomly selected signatures
correct_guess = 0

for i in range(10):
    display(HTML(f"<h1 style='font-size:15px; color:orange;'>TEST {i+1}</h1>"))
    path1, path2, label, img1, img2, distance, similarity_score = model_prediction_function(model, csv_path, data_dir)
    print_result(path1, path2, label, distance, similarity_score)
    if label == 0:
        correct_guess += 1 if similarity_score >= 0.6 else 0
    else:
        correct_guess += 1 if similarity_score < 0.6 else 0

correct_rate = correct_guess * 10
print("-------------------------------------------------------")
display(HTML(f"<h1 style='font-size:20px; color:#5aaaff;'>-> 10 RANDOM TESTS - ACCURACY RATE: {correct_rate}%</h1>"))

"""### Different Single Sample Test"""

# define paths, process images and make a prediction with the model
path1 = f"{project_path}/trial_signs/sign_org_1_1.jpg"
path2 = f"{project_path}/trial_signs/sign_org_1_2.jpg"

img1 = process_single_image(path1, img_size)
img2 = process_single_image(path2, img_size)

tmp_img1 = np.expand_dims(img1, axis=0)
tmp_img2 = np.expand_dims(img2, axis=0)

distance = model.predict([tmp_img1, tmp_img2])

similarity_score = calculate_similarity_score(distance)

# display distance
print(f"{distance[0][0]:.3f}")

# display similarity score
print(f"{similarity_score:.3f}")

# view signatures
display_images(img1, img2)

"""## Tests on Trial Dataset"""

# read csv file
csv_path_trial = f"{data_trial_dir}/trial_data_comparison.csv"
trial_data_csv = pd.read_csv(csv_path_trial, header=None, names=columns)

# process the data
trial_X, trial_y = process_data(trial_data_csv, data_trial_dir, img_size)

# display statistical summary of the dataset
trial_data_csv.describe().T

# print the class distribution in the dataset
class_distribution = trial_data_csv['Label'].value_counts()

print("Class Distribution in the Dataset")

for label, count in class_distribution.items():
    print(f"- (all)   frequency of class {label}: {count}")

# save the data
np.save(f"{data_notebook_dir}/trial_X.npy", trial_X)
np.save(f"{data_notebook_dir}/trial_y.npy", trial_y)

# load the data
trial_X = np.load(f"{data_notebook_dir}/trial_X.npy")
trial_y = np.load(f"{data_notebook_dir}/trial_y.npy")

# evaluate the model on different test set
results_trial = model.evaluate([trial_X[:, 0], trial_X[:, 1]], trial_y)
print(f"-> Loss in Trial Data\t\t: {results_trial[0]:.5f}")
print(f"-> Accuracy in Trial Data\t: {results_trial[2]:.5f}\n")

# confusion Matrix for Trial Dataset
display_confusion_matrix(model, trial_X, trial_y)

# estimate the similarity rate between randomly selected signatures
correct_guess = 0

for i in range(10):
    display(HTML(f"<h1 style='font-size:15px; color:orange;'>TEST {i+1}</h1>"))
    path1, path2, label, img1, img2, distance, similarity_score = model_prediction_function(model, csv_path_trial, data_trial_dir)
    print_result(path1, path2, label, distance, similarity_score)
    if label == 0:
        correct_guess += 1 if similarity_score >= 0.6 else 0
    else:
        correct_guess += 1 if similarity_score < 0.6 else 0

correct_rate = correct_guess * 10
print("-------------------------------------------------------")
display(HTML(f"<h1 style='font-size:20px; color:#5aaaff;'>-> 10 RANDOM TESTS - ACCURACY RATE: {correct_rate}%</h1>"))
